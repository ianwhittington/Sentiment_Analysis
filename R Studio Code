## Ian Whittington
## Assignment 3 
## DATA 650
## Professor Ozcan
## 3/11/2025




GOP_SENTIMENT<- read.csv("~/project-objectstorage/First_GOP_Debate.csv", stringsAsFactors=FALSE)
#Check the row counts
nrow(GOP_SENTIMENT)


# View first few rows
head(GOP_SENTIMENT)


# Summary of numerical and categorical data
summary(GOP_SENTIMENT)

# Check unique sentiment values
unique(GOP_SENTIMENT$sentiment)



#number of tweets per sentiment
table(GOP_SENTIMENT$SENTIMENT)

#number of tweets per candidate
table(GOP_SENTIMENT$CANDIDATE)

#number of tweets per sentiment by candidate
table(GOP_SENTIMENT$CANDIDATE, GOP_SENTIMENT$SENTIMENT)

#Pie charts
#Reset the margin
par(mar=c(1,1,1,1))
#Use default colors
pie (table(GOP_SENTIMENT$CANDIDATE))
#Change colors
pie (table(GOP_SENTIMENT$CANDIDATE), col=c("blue", "yellow", "green", "purple", "pink", "orange", "tan", "red", "gray", "lightblue", "white", "lightcyan"))

#load the plyr package
library("plyr")
#List the most common complaints
reasonCounts<-na.omit(plyr::count(GOP_SENTIMENT$SUBJECT_MATTER))
reasonCounts<-reasonCounts[order(reasonCounts$freq, decreasing=TRUE), ]
reasonCounts

# Using ggplot2 package
# Complaints frequency plot
library(ggplot2)
wf <- data.frame(reasonCounts)
p <- ggplot(wf, aes(wf$x, wf$freq))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
p



#Number of retweets per subject matter
ddply(GOP_SENTIMENT, ~ SUBJECT_MATTER, summarize, numRetweets = sum(RETWEET_COUNT, na.rm = TRUE))

#Posts that have 6 retweets
as.character(subset(SENTIMENT, RETWEET_COUNT ==6)$TEXT)

#number of posts per day
posts<-as.Date(GOP_SENTIMENT$TWEET_CREATED, tryFormats = c("%Y-%m-%d", "%Y/%m/%d", "%m/%d/%Y"),optional = FALSE)
table(posts)
#day with the maximum number of posts
table(posts)[which.max(table(posts))]

#number of posts per day by sentiment plot
library (dplyr)

drs<-GOP_SENTIMENT[, c('TWEET_CREATED', 'SENTIMENT')]

drs$TWEET_CREATED<- as.Date(drs$TWEET_CREATED, tryFormats = c("%Y-%m-%d", "%Y/%m/%d", "%m/%d/%Y"),optional = FALSE)
# Calculate and plot number of tweets per day by candidate
ByDateBySent <- drs %>% group_by(SENTIMENT,TWEET_CREATED) %>% dplyr::summarise(count = n())
ByDateBySentPlot = ggplot() + geom_line(data=ByDateBySent, aes(x=TWEET_CREATED, y=count, group =SENTIMENT , color=SENTIMENT)) 
ByDateBySentPlot


#Text Mining
#install tm, wordcloud, SnowballC for stemming.  Do it only once.
install.packages("tm")
install.packages("SnowballC")
install.packages("wordcloud")


#Load the packages in memory
library("tm")
library("wordcloud")
library ("SnowballC")


#Load the tweets with negative sentiment into the data frame negative
negative <- GOP_SENTIMENT[GOP_SENTIMENT$SENTIMENT == 'Negative', c('TEXT'), drop = FALSE]

docs<-VectorSource(negative$TEXT)
docs<-Corpus(docs)


docs[[1]]$content
docs[[2]]$content
docs[[20]]$content

#Strip the white space
docs <- tm_map(docs, stripWhitespace)


#Remove the URLs
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
docs <- tm_map(docs, content_transformer(removeURL))


#Remove non ASCII character
removeInvalid<-function(x) gsub("[^\x01-\x7F]", "", x)
docs <- tm_map(docs, content_transformer(removeInvalid))


#Remove punctuation
docs <- tm_map(docs, removePunctuation)


#remove the numbers
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)

toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "@")   #Remove @
docs <- tm_map(docs, toSpace, "/")   #Remove /
docs <- tm_map(docs, toSpace, "\\|") #Remove |


#Remove the stop word
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, stopwords("SMART"))


docs <- tm_map(docs, stemDocument)


#Remove the white space introduced during the pre-processing
docs <- tm_map(docs, stripWhitespace)
dtm <- DocumentTermMatrix(docs)

m <- as.matrix(dtm)   #Convert dtm to a matrix
dim(m)                # Display number of terms and number of documents
View(m[1:10, 1:10])   # Preview the first 10 rows and the first 10 columns in m

#find the terms that appear at least 50 times
findFreqTerms(dtm, lowfreq=50)
#find the terms asosciated with bad and worst with correlation at least 0.15
findAssocs(dtm, c("bad", "worst"), corlimit=0.15)

dtms <- removeSparseTerms(dtm, 0.6) # Prepare the data (max 60% empty space)   
freq <- colSums(as.matrix(dtm)) # Find word frequencies   
dark2 <- brewer.pal(6, "Dark2")   
wordcloud(names(freq), freq, min.freq=50, max.words=100, rot.per=0.2, scale=c(0.9, 0.9), colors=dark2)    

# Terms Cluster dendogram
library("cluster")

dtms <- removeSparseTerms(dtm, 0.98)    #Remove sparse terms
d <- dist(t(dtms), method="euclidian")  #Build the dissimilarity matrix
fit <- hclust(d=d, method="ward.D2")
plot(fit, hang=-1)

#Network of terms
library ("igraph")
tdm<-TermDocumentMatrix(docs)              # Term document matrix
tdm <- removeSparseTerms(tdm, 0.96)        # Remove sparse terms
termDocMatrix <- as.matrix(tdm)            # Convert tdm to matrix

termDocMatrix[termDocMatrix>=1] <- 1       # Set non-zero entries to 1 (1=term present, 0=term absent)
termMatrix <- termDocMatrix %*% t(termDocMatrix)   
View (termMatrix)

g <- graph.adjacency(termMatrix, weighted=T, mode="undirected")
g <- simplify(g)                 # Remove the self-relationships
# V(g) is a graph vertex
V(g)$label <- V(g)$name          # Label each vertex with a term
V(g)$degree <- degree(g)
set.seed(3952)

plot(g, layout=layout_nicely(g), vertex.color="plum", vertex.size=25)


cl <- maximal.cliques(g)
cl

colbar <- rainbow(length(cl) + 1) 
for (i in 1:length(cl)) {V(g)[cl[[i]]]$color <- colbar[i+1] }
plot(g, mark.groups=cl,vertex.size=.3, vertex.label.cex=1.2, edge.color=rgb(.4,.4,0,.3))

# Count mentions of each user
mentions <- table(unlist(str_extract_all(GOP_SENTIMENT$TEXT, "@\\w+")))

# Convert to data frame for easier handling
mention_df <- as.data.frame(mentions, stringsAsFactors = FALSE)
colnames(mention_df) <- c("User", "Count")

# Get top 10 mentioned users
top_mentions <- head(mention_df[order(-mention_df$Count), ], 10)

# Plot bar chart with proper labels
barplot(top_mentions$Count, 
        names.arg = top_mentions$User, 
        las = 2, 
        col = "steelblue", 
        main = "Top Mentioned Users", 
        cex.names = 0.8)  # Adjust text size if needed

